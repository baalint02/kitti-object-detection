{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kitti_detection import config\n",
    "from kitti_detection.dataset import DataSample, class_names, load_train_val_test_dataset\n",
    "from kitti_detection.utils import display_samples_h, generalized_box_iou, box_cxcywh_to_xyxy\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn, optim, Tensor\n",
    "from torch.nested import nested_tensor\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import v2\n",
    "from torchvision.tv_tensors import BoundingBoxes\n",
    "\n",
    "from scipy.optimize import linear_sum_assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = v2.Compose([\n",
    "    v2.RandomCrop(size=(370, 370)),\n",
    "    v2.SanitizeBoundingBoxes(),\n",
    "    v2.ToDtype(torch.float32),\n",
    "    v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset, test_dataset = load_train_val_test_dataset()\n",
    "\n",
    "train_dataset.transform = transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = len(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p(t):\n",
    "    print(t)\n",
    "    print(t.size())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_1d_pos_encoding(l, dim):\n",
    "    return torch.cat([\n",
    "        torch.stack([\n",
    "            torch.linspace(0, 10000**(2*i/dim), steps=l).sin(),\n",
    "            torch.linspace(0, 10000**(2*i/dim), steps=l).cos()\n",
    "        ], dim=1)\n",
    "        for i in range(dim // 2)\n",
    "    ], dim=1)\n",
    "\n",
    "def create_pos_encoding(h, w, dim):\n",
    "    col_embed = get_1d_pos_encoding(w, dim // 2).repeat(h, 1, 1)\n",
    "    row_embed = get_1d_pos_encoding(h, dim // 2).unsqueeze(1).repeat(1, w, 1)\n",
    "    \n",
    "    return torch.cat((col_embed, row_embed), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DETR(nn.Module):\n",
    "\n",
    "    def __init__(self, dim_embed=256):\n",
    "        super().__init__()\n",
    "        self.backbone = self._backbone()\n",
    "        self.conv = nn.Conv2d(512, dim_embed, kernel_size=1)\n",
    "\n",
    "        self.register_buffer('pos_embedding', create_pos_encoding(12, 12, dim_embed)) # (12, 12, 256)\n",
    "        self.register_buffer('query_pos_embedding', get_1d_pos_encoding(20, dim_embed))\n",
    "\n",
    "        self.transformer = nn.Transformer(dim_embed, nhead=8, num_encoder_layers=4, num_decoder_layers=4, batch_first=True)\n",
    "\n",
    "        self.linear_class = nn.Linear(dim_embed, n_classes + 1)\n",
    "        self.linear_bbox = nn.Linear(dim_embed, 4)\n",
    "\n",
    "    def _backbone(self) -> nn.Module:\n",
    "        backbone = torchvision.models.resnet18(weights=torchvision.models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "        del backbone.fc\n",
    "        del backbone.avgpool\n",
    "\n",
    "        def _forward(bb: torchvision.models.ResNet, x):\n",
    "            x = bb.conv1(x)\n",
    "            x = bb.bn1(x)\n",
    "            x = bb.relu(x)\n",
    "            x = bb.maxpool(x)\n",
    "\n",
    "            x = bb.layer1(x)\n",
    "            x = bb.layer2(x)\n",
    "            x = bb.layer3(x)\n",
    "            x = bb.layer4(x)\n",
    "            return x\n",
    "\n",
    "        backbone.forward = lambda x: _forward(backbone, x)\n",
    "        # TODO BatchNorm freeze\n",
    "        return backbone\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = self.backbone(input) # (4, 512, 12, 12)\n",
    "        x = self.conv(x) # (4, 256, 12, 12)\n",
    "\n",
    "        x = x.permute(0, 2, 3, 1) # (4, 12, 12, 256)\n",
    "        x = x + self.pos_embedding\n",
    "        x = x.flatten(1, 2) # (4, 144, 256)\n",
    "\n",
    "        q = self.query_pos_embedding.repeat(4, 1, 1) # (4, 20, 256)\n",
    "        q = self.transformer(x, q)\n",
    "\n",
    "        return {\n",
    "            'pred_logits': self.linear_class(q),\n",
    "            'pred_boxes': torch.sigmoid(self.linear_bbox(q))\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _collate(samples):\n",
    "    imgs = tuple( img for img, _ in samples )\n",
    "    targets = tuple( target for _, target in samples )\n",
    "    return torch.stack(imgs), tuple(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs, targets = next(iter(data_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DETR()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad\n",
    "def match_indices(outputs: torch.Tensor, targets: torch.Tensor, cost_bbox_factor=0.3, cost_class_factor=0.3, cost_giou_factor=0.3):\n",
    "    \"\"\" Performs the matching\n",
    "\n",
    "    Params:\n",
    "        outputs: This is a dict that contains at least these entries:\n",
    "                \"pred_logits\": Tensor of dim [batch_size, num_queries, num_classes] with the classification logits\n",
    "                \"pred_boxes\": Tensor of dim [batch_size, num_queries, 4] with the predicted box coordinates\n",
    "\n",
    "        targets: This is a list of targets (len(targets) = batch_size), where each target is a dict containing:\n",
    "                \"labels\": Tensor of dim [num_target_boxes] (where num_target_boxes is the number of ground-truth\n",
    "                        objects in the target) containing the class labels\n",
    "                \"boxes\": Tensor of dim [num_target_boxes, 4] containing the target box coordinates\n",
    "\n",
    "    Returns:\n",
    "        A list of size batch_size, containing tuples of (index_i, index_j) where:\n",
    "            - index_i is the indices of the selected predictions (in order)\n",
    "            - index_j is the indices of the corresponding selected targets (in order)\n",
    "        For each batch element, it holds:\n",
    "            len(index_i) = len(index_j) = min(num_queries, num_target_boxes)\n",
    "    \"\"\"\n",
    "    bs, num_queries = outputs[\"pred_logits\"].shape[:2]\n",
    "\n",
    "    # We flatten to compute the cost matrices in a batch\n",
    "    out_prob = outputs[\"pred_logits\"].flatten(0, 1).softmax(-1)  # [batch_size * num_queries, num_classes]\n",
    "    out_bbox = outputs[\"pred_boxes\"].flatten(0, 1)  # [batch_size * num_queries, 4]\n",
    "\n",
    "    # Also concat the target labels and boxes\n",
    "    tgt_ids = torch.cat([v[\"labels\"] for v in targets])\n",
    "    tgt_bbox = torch.cat([v[\"boxes\"] for v in targets])\n",
    "\n",
    "    # Compute the classification cost. Contrary to the loss, we don't use the NLL,\n",
    "    # but approximate it in 1 - proba[target class].\n",
    "    # The 1 is a constant that doesn't change the matching, it can be ommitted.\n",
    "    cost_class = -out_prob[:, tgt_ids]\n",
    "\n",
    "    # Compute the L1 cost between boxes\n",
    "    cost_bbox = torch.cdist(out_bbox, tgt_bbox, p=1)\n",
    "\n",
    "    # Compute the giou cost betwen boxes\n",
    "    cost_giou = -generalized_box_iou(box_cxcywh_to_xyxy(out_bbox), box_cxcywh_to_xyxy(tgt_bbox))\n",
    "\n",
    "    # Final cost matrix\n",
    "    C = cost_bbox_factor * cost_bbox + cost_class_factor * cost_class + cost_giou_factor * cost_giou\n",
    "    C = C.view(bs, num_queries, -1).cpu()\n",
    "\n",
    "    sizes = [len(v[\"boxes\"]) for v in targets]\n",
    "    indices = [linear_sum_assignment(c[i].detach()) for i, c in enumerate(C.split(sizes, -1))]\n",
    "    return [(torch.as_tensor(i, dtype=torch.int64), torch.as_tensor(j, dtype=torch.int64)) for i, j in indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(imgs)\n",
    "#match_indices(output, targets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 20, 10])\n"
     ]
    }
   ],
   "source": [
    "print(output[\"pred_logits\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = match_indices(output, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 0, 1, 1, 1, 2, 2, 3, 3, 3, 3, 3]),\n",
       " tensor([ 2, 15,  0,  2,  5,  0, 16,  0,  1,  9, 15, 18]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def _get_src_permutation_idx(indices):\n",
    "        # permute predictions following indices\n",
    "        batch_idx = torch.cat([torch.full_like(src, i) for i, (src, _) in enumerate(indices)])\n",
    "        src_idx = torch.cat([src for (src, _) in indices])\n",
    "        return batch_idx, src_idx\n",
    "\n",
    "\n",
    "_get_src_permutation_idx(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HungarianLoss(nn.Module):\n",
    "    def loss_labels(self, outputs, targets, indices):\n",
    "        pred_logits = outputs['pred_logits']\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 9\n",
    "empty_weight = torch.ones(num_classes + 1)\n",
    "eofs_coef = 0.1\n",
    "empty_weight[-1] = eofs_coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "        0.1000])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "empty_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def loss_labels(outputs, targets, indices):\n",
    "    \"\"\"Classification loss (NLL)\n",
    "    targets dicts must contain the key \"labels\" containing a tensor of dim [nb_target_boxes]\n",
    "    \"\"\"\n",
    "    assert 'pred_logits' in outputs\n",
    "    src_logits = outputs['pred_logits']\n",
    "\n",
    "    idx = _get_src_permutation_idx(indices)\n",
    "    target_classes_o = torch.cat([t[\"labels\"][J] for t, (_, J) in zip(targets, indices)])\n",
    "    target_classes = torch.full(src_logits.shape[:2], num_classes,\n",
    "                                dtype=torch.int64, device=src_logits.device)\n",
    "    target_classes[idx] = target_classes_o\n",
    "\n",
    "    loss_ce = F.cross_entropy(src_logits.transpose(1, 2), target_classes, weight=empty_weight)\n",
    "    losses = {'loss_ce': loss_ce}\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_labels(output, targets, indices)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
