{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kitti_detection import config\n",
    "from kitti_detection.dataset import DataSample, class_names, load_train_val_test_dataset\n",
    "from kitti_detection.utils import display_samples_h\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn, optim, Tensor\n",
    "from torch.nested import nested_tensor\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import v2\n",
    "from torchvision.tv_tensors import BoundingBoxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = v2.Compose([\n",
    "    v2.RandomCrop(size=(370, 370)),\n",
    "    v2.SanitizeBoundingBoxes(),\n",
    "    v2.ToDtype(torch.float32),\n",
    "    v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p(t):\n",
    "    print(t)\n",
    "    print(t.size())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DETR(nn.Module):\n",
    "\n",
    "    def __init__(self, dim_embed=256):\n",
    "        self.backbone = self._backbone()\n",
    "        self.conv = nn.Conv2d(512, 256, kernel_size=1)\n",
    "\n",
    "        self.register_buffer('pos_embedding', create_pos_encoding(12, 12)) # (12, 12, 256)\n",
    "        self.register_buffer('query_pos_embedding', get_1d_pos_encoding(20, dim_embed))\n",
    "\n",
    "        self.transformer = nn.Transformer(dim_embed, nhead=8, num_encoder_layers=4, num_decoder_layers=4, batch_first=True)\n",
    "\n",
    "        self.linear_class = nn.Linear(dim_embed, n_classes + 1)\n",
    "        self.linear_bbox = nn.Linear(dim_embed, 4)\n",
    "        super().__init__()\n",
    "\n",
    "    def _backbone(self) -> nn.Module:\n",
    "        backbone = torchvision.models.resnet18(weights=torchvision.models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "        del backbone.fc\n",
    "        del backbone.avgpool\n",
    "\n",
    "        def _forward(bb: torchvision.models.ResNet, x):\n",
    "            x = bb.conv1(x)\n",
    "            x = bb.bn1(x)\n",
    "            x = bb.relu(x)\n",
    "            x = bb.maxpool(x)\n",
    "\n",
    "            x = bb.layer1(x)\n",
    "            x = bb.layer2(x)\n",
    "            x = bb.layer3(x)\n",
    "            x = bb.layer4(x)\n",
    "            return x\n",
    "\n",
    "        backbone.forward = lambda x: _forward(backbone, x)\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = self.backbone(input)\n",
    "        print(x.size())\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset, test_dataset = load_train_val_test_dataset()\n",
    "\n",
    "train_dataset.transform = transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = len(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = DataLoader(train_dataset, batch_size=None, shuffle=True)\n",
    "#display_samples_h([next(iter(data_loader)) for _ in range(4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 370, 370])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(data_loader))[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_batch = torch.stack([next(iter(data_loader))[0] for _ in range(4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3, 370, 370])\n"
     ]
    }
   ],
   "source": [
    "print(input_batch.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_embed = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_1d_pos_encoding(l, dim):\n",
    "    return torch.cat([\n",
    "        torch.stack([\n",
    "            torch.linspace(0, 10000**(2*i/dim), steps=l).sin(),\n",
    "            torch.linspace(0, 10000**(2*i/dim), steps=l).cos()\n",
    "        ], dim=1)\n",
    "        for i in range(dim // 2)\n",
    "    ], dim=1)\n",
    "\n",
    "def create_pos_encoding(h, w, dim):\n",
    "    col_embed = get_1d_pos_encoding(w, dim // 2).repeat(h, 1, 1)\n",
    "    row_embed = get_1d_pos_encoding(h, dim // 2).unsqueeze(1).repeat(1, w, 1)\n",
    "    \n",
    "    return torch.cat((col_embed, row_embed), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 256])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_pos_embedding.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = backbone(input_batch) # (4, 512, 12, 12)\n",
    "x = conv(x) # (4, 256, 12, 12)\n",
    "\n",
    "x = x.permute(0, 2, 3, 1) # (4, 12, 12, 256)\n",
    "x = x + pos_embedding\n",
    "x = x.flatten(1, 2) # (4, 144, 256)\n",
    "\n",
    "q = query_pos_embedding.repeat(4, 1, 1) # (4, 20, 256)\n",
    "\n",
    "q = transformer(x, q)\n",
    "\n",
    "pred_logits = linear_class(q)\n",
    "pred_bboxes = torch.sigmoid(linear_bbox(q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.2989, 0.3752, 0.6840, 0.2632],\n",
      "         [0.3852, 0.2919, 0.7943, 0.4567],\n",
      "         [0.3604, 0.3874, 0.8037, 0.4133],\n",
      "         [0.2853, 0.3429, 0.7407, 0.5648],\n",
      "         [0.3136, 0.4665, 0.6625, 0.3559],\n",
      "         [0.4037, 0.4302, 0.8041, 0.3987],\n",
      "         [0.2630, 0.4818, 0.7175, 0.2959],\n",
      "         [0.2425, 0.4006, 0.7613, 0.3108],\n",
      "         [0.2651, 0.3428, 0.7743, 0.3723],\n",
      "         [0.4702, 0.4934, 0.7538, 0.3022],\n",
      "         [0.3149, 0.3545, 0.6274, 0.4723],\n",
      "         [0.4575, 0.3948, 0.6069, 0.4462],\n",
      "         [0.4119, 0.5753, 0.6982, 0.4272],\n",
      "         [0.3378, 0.4335, 0.6368, 0.3993],\n",
      "         [0.3655, 0.3129, 0.7284, 0.4467],\n",
      "         [0.3443, 0.4044, 0.8465, 0.3359],\n",
      "         [0.3950, 0.4006, 0.7266, 0.4710],\n",
      "         [0.2930, 0.2794, 0.7905, 0.4170],\n",
      "         [0.2964, 0.4281, 0.5667, 0.4747],\n",
      "         [0.3113, 0.3822, 0.7032, 0.4106]],\n",
      "\n",
      "        [[0.3520, 0.3492, 0.6631, 0.3911],\n",
      "         [0.2674, 0.3208, 0.8503, 0.3617],\n",
      "         [0.3668, 0.2737, 0.7978, 0.2949],\n",
      "         [0.4237, 0.3250, 0.7374, 0.3949],\n",
      "         [0.3776, 0.5311, 0.6903, 0.2969],\n",
      "         [0.3361, 0.4065, 0.7466, 0.2781],\n",
      "         [0.3498, 0.4679, 0.7648, 0.2388],\n",
      "         [0.4528, 0.4028, 0.7955, 0.2994],\n",
      "         [0.3800, 0.4037, 0.7800, 0.3297],\n",
      "         [0.3861, 0.3920, 0.7716, 0.3729],\n",
      "         [0.3607, 0.4304, 0.7426, 0.4022],\n",
      "         [0.3534, 0.4927, 0.7068, 0.3270],\n",
      "         [0.4535, 0.5074, 0.7147, 0.3954],\n",
      "         [0.4204, 0.4141, 0.7088, 0.3451],\n",
      "         [0.3775, 0.3244, 0.7991, 0.2857],\n",
      "         [0.3882, 0.3910, 0.7806, 0.4459],\n",
      "         [0.4929, 0.3067, 0.7547, 0.3954],\n",
      "         [0.2859, 0.3432, 0.7511, 0.2828],\n",
      "         [0.2591, 0.3666, 0.7051, 0.3101],\n",
      "         [0.3895, 0.4432, 0.7412, 0.4242]],\n",
      "\n",
      "        [[0.3173, 0.3291, 0.7579, 0.2788],\n",
      "         [0.3947, 0.4050, 0.7419, 0.3464],\n",
      "         [0.4996, 0.4055, 0.8641, 0.4204],\n",
      "         [0.3974, 0.4364, 0.7746, 0.4279],\n",
      "         [0.5314, 0.4112, 0.7932, 0.4159],\n",
      "         [0.5088, 0.4275, 0.7977, 0.3429],\n",
      "         [0.3595, 0.4454, 0.6906, 0.2827],\n",
      "         [0.4132, 0.4204, 0.8045, 0.2648],\n",
      "         [0.3557, 0.4370, 0.8050, 0.3719],\n",
      "         [0.3398, 0.3764, 0.8022, 0.3908],\n",
      "         [0.4580, 0.3302, 0.7620, 0.5495],\n",
      "         [0.5275, 0.4724, 0.7590, 0.4097],\n",
      "         [0.5579, 0.5707, 0.6875, 0.4108],\n",
      "         [0.3461, 0.4031, 0.7777, 0.3910],\n",
      "         [0.4037, 0.3940, 0.7754, 0.3678],\n",
      "         [0.5078, 0.5346, 0.8190, 0.4641],\n",
      "         [0.5076, 0.4175, 0.7625, 0.4231],\n",
      "         [0.3555, 0.3748, 0.7657, 0.3708],\n",
      "         [0.3738, 0.4557, 0.7383, 0.4213],\n",
      "         [0.3664, 0.5943, 0.7482, 0.4632]],\n",
      "\n",
      "        [[0.4267, 0.3363, 0.4801, 0.3567],\n",
      "         [0.4801, 0.4883, 0.7186, 0.3962],\n",
      "         [0.5369, 0.4552, 0.7310, 0.3946],\n",
      "         [0.4645, 0.4292, 0.6772, 0.4264],\n",
      "         [0.4719, 0.3944, 0.6270, 0.4756],\n",
      "         [0.4381, 0.4073, 0.8043, 0.4401],\n",
      "         [0.3727, 0.4084, 0.6230, 0.3804],\n",
      "         [0.4819, 0.3199, 0.7094, 0.2824],\n",
      "         [0.3304, 0.3696, 0.7434, 0.4790],\n",
      "         [0.5115, 0.3525, 0.7561, 0.3778],\n",
      "         [0.3925, 0.2893, 0.7169, 0.5480],\n",
      "         [0.5231, 0.4161, 0.7002, 0.5077],\n",
      "         [0.5741, 0.5336, 0.7409, 0.4701],\n",
      "         [0.4401, 0.3449, 0.6913, 0.4529],\n",
      "         [0.4122, 0.3851, 0.7063, 0.4038],\n",
      "         [0.4789, 0.4951, 0.7357, 0.4917],\n",
      "         [0.5847, 0.3471, 0.7560, 0.5145],\n",
      "         [0.3399, 0.4033, 0.7241, 0.3905],\n",
      "         [0.4865, 0.4480, 0.6669, 0.3888],\n",
      "         [0.4157, 0.5186, 0.8094, 0.3278]]], grad_fn=<SigmoidBackward0>)\n",
      "torch.Size([4, 20, 4])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "p(pred_bboxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "print(n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(n_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
